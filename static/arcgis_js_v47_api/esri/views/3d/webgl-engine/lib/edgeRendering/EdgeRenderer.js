// All material copyright ESRI, All Rights Reserved, unless otherwise specified.
// See https://js.arcgis.com/4.7/esri/copyright.txt for details.
//>>built
require({cache:{"url:esri/views/3d/webgl-engine/lib/edgeRendering/EdgeRendererUtils.xml":'\x3c?xml version\x3d"1.0" encoding\x3d"UTF-8"?\x3e\r\n\r\n\x3csnippets\x3e\r\n\r\n\x3csnippet name\x3d"EdgeRendererUtils_distanceBasedPerspectiveFactor"\x3e\x3c![CDATA[\r\n  uniform float uDistanceFalloffFactor;\r\n\r\n  float distanceBasedPerspectiveFactor(float distance) {\r\n    return clamp(sqrt(uDistanceFalloffFactor / distance), 0.0, 1.0);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"EdgeRendererUtils_readComponentColor"\x3e\x3c![CDATA[\r\n  uniform sampler2D uComponentColorTex;\r\n  uniform vec2 uComponentColorTexInvDim;\r\n\r\n  attribute float componentIndex;\r\n\r\n  vec4 readComponentColor() {\r\n    float normalizedIndex \x3d (componentIndex + 0.5) * uComponentColorTexInvDim.x;\r\n    vec2 indexCoord \x3d vec2(\r\n      mod(normalizedIndex, 1.0),\r\n      (floor(normalizedIndex) + 0.5) * uComponentColorTexInvDim.y\r\n    );\r\n    return texture2D(uComponentColorTex, indexCoord);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"EdgeRendererUtils_isSilhouetteEdge"\x3e\x3c![CDATA[\r\n  // #uniforms: uView, uModel\r\n  // #attributes: normalA, normalB\r\n  bool isSilhouetteEdge(vec4 viewPos) {\r\n    // transform the two face normals\r\n    vec3 viewNormalA \x3d (uView * uModel * vec4(normalA, 0.0)).xyz;\r\n    vec3 viewNormalB \x3d (uView * uModel * vec4(normalB, 0.0)).xyz;\r\n\r\n    // compute the direction from the edge to the camera\r\n    vec3 viewDir \x3d -viewPos.xyz;\r\n\r\n    // check which of the two faces are visible\r\n    // display the edge if exactly one of the two is visible\r\n    float faceAVisible \x3d dot(viewDir, viewNormalA); // positive if visible\r\n    float faceBVisible \x3d dot(viewDir, viewNormalB); // positive if visible\r\n\r\n    // 1 if exactly one face visible, 0 otherwise\r\n    return faceAVisible * faceBVisible \x3c 0.0;\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"EdgeRendererUtils_adjustProjectedPosition"\x3e\x3c![CDATA[\r\n  uniform vec2 uDepthBias;\r\n  uniform vec2 uViewportDimInv;\r\n\r\n  // Utility function to check for NaN values\r\n  bool isNaN(float val) {\r\n    return ( val \x3c 0.0 || 0.0 \x3c val || val \x3d\x3d 0.0 ) ? false : true;\r\n    // important: some nVidias failed to cope with version below.\r\n    // Probably wrong optimization.\r\n    /*return ( val \x3c\x3d 0.0 || 0.0 \x3c\x3d val ) ? false : true;*/\r\n  }\r\n\r\n  // An offset in xy screen space, along the projected normal of the edge\r\n  // This reduces depth fighting when looking at a face from a flat angle\r\n  vec2 calculateProjectedBiasXY(vec4 projPos, vec3 worldNormal) {\r\n    float offsetXY \x3d uDepthBias.x;\r\n    float offsetZ  \x3d uDepthBias.y;\r\n\r\n    // screen space pixel offset\r\n    // we multiply by two to account for the fact that NDC go from -1 to 1\r\n    // we multiply by projPos.w to compensate for the perspective divison that happens later\r\n    // normalizing over xyz means that the xy influence is reduced the more the normal is pointing\r\n    // towards the camera\r\n    vec4 projNormal \x3d uProj * uView * vec4(worldNormal, 0.0);\r\n\r\n    return offsetXY * projPos.w * 2.0 * uViewportDimInv * normalize(projNormal.xyz).xy;\r\n  }\r\n\r\n  // A z-offset, using a depth based heuristic.\r\n  float calculateProjectedBiasZ(vec4 projPos) {\r\n    float offsetZ \x3d uDepthBias.y;\r\n    return sqrt(projPos.z) * offsetZ;\r\n  }\r\n\r\n  vec4 adjustProjectedPosition(vec4 projPos, vec3 worldNormal, float lineWidth) {\r\n    vec2 offsetXY \x3d calculateProjectedBiasXY(projPos, worldNormal);\r\n\r\n    // we currently have to do this check because some geometries come with 0 length edge normals.\r\n    // see https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/12890\r\n    if (!isNaN(offsetXY.x) \x26\x26 !isNaN(offsetXY.y)) {\r\n      projPos.xy +\x3d offsetXY;\r\n    }\r\n\r\n    projPos.z +\x3d calculateProjectedBiasZ(projPos) * lineWidth;\r\n\r\n    return projPos;\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"EdgeRendererUtils_worldNormal"\x3e\x3c![CDATA[\r\n  vec3 modelToWorldNormal(vec3 normal) {\r\n    return (uModel * vec4(normal, 0)).xyz;\r\n  }\r\n\r\n  vec3 silhouetteWorldNormal(vec3 normalA, vec3 normalB) {\r\n    return modelToWorldNormal(normalize(normalA + normalB));\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"EdgeRendererUtils_extensionFalloff"\x3e\x3c![CDATA[\r\n  // Fall-off extension length for shorter strokes, starting from strokes that are 256 size,\r\n  // fall-off exponentially\r\n  float calculateExtensionLength(float extensionLength, float lineLength) {\r\n    return extensionLength / (log2(max(1.0, 256.0 / lineLength)) * 0.2 + 1.0);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3c/snippets\x3e\r\n'}});
define("require exports ../../../../../core/tsSupport/assignHelper dojo/text!./EdgeRendererUtils.xml ../../../support/buffer/glUtil ../../../support/buffer/InterleavedLayout ./edgePreprocessing ../../../../webgl/BufferObject ../../../../webgl/VertexArrayObject".split(" "),function(e,c,n,p,q,r,t,f,l){Object.defineProperty(c,"__esModule",{value:!0});var m=r.newLayout().vec2u8("sidenessAtt");c.glVertexLayout=q.glLayout(m);e=function(){function d(b,a,c){this.rctx=b;this.programRepository=a;this.key=c;
this.depthBiasZ=-4E-4;this.depthBiasXY=.5;b=m.createBuffer(4);for(a=0;4>a;a++)b.sidenessAtt.set(a,0,0===a||3===a?0:1),b.sidenessAtt.set(a,1,0===a||1===a?0:1);this.verticesBufferObject=f.createVertex(this.rctx,35044,b.buffer)}d.prototype.dispose=function(){for(var b in this.programs){var a=this.programs[b];a&&(this.programRepository.decreaseRefCount(a),this.programs[b]=null)}this.verticesBufferObject&&(this.verticesBufferObject.dispose(),this.verticesBufferObject=null)};d.prototype.createInstance=
function(b,a,d){a=t.extractEdges(a,this.edgeBufferWriters.default.writer,this.edgeBufferWriters.silhouette.writer);var e=a.averageEdgeLength,g=null,h=null,k=0;0<a.edge.lodInfo.lengths.length&&(g=new l(this.rctx,c.attributeLocations,{vertices:c.glVertexLayout,instances:this.edgeBufferWriters.default.glLayout},{vertices:this.verticesBufferObject,instances:f.createVertex(this.rctx,35044,a.edge.instancesData.buffer)}),k+=g.size);0<a.silhouette.lodInfo.lengths.length&&(h=new l(this.rctx,c.attributeLocations,
{vertices:c.glVertexLayout,instances:this.edgeBufferWriters.silhouette.glLayout},{vertices:this.verticesBufferObject,instances:f.createVertex(this.rctx,35044,a.silhouette.instancesData.buffer)}),k+=h.size);return n({},b,{edgeVAO:g,silhouetteVAO:h,material:d,averageEdgeLength:e,gpuMemoryUsage:k,edgeLoD:a.edge.lodInfo,silhouetteLoD:a.silhouette.lodInfo})};d.prototype.disposeInstance=function(b){b.edgeVAO&&(b.edgeVAO.vertexBuffers.instances.dispose(),b.edgeVAO.dispose(!1),b.edgeVAO=null);b.silhouetteVAO&&
(b.silhouetteVAO.vertexBuffers.instances.dispose(),b.silhouetteVAO.dispose(!1),b.silhouetteVAO=null)};d.prototype.addProgram=function(b,a){this.programs||(this.programs={});this.programs[b]=a;this.programRepository.increaseRefCount(a)};d.loadShaders=function(b,a,c){b.EdgeRendererUtils_readComponentColor||b._parse(p)};return d}();c.EdgeRenderer=e;c.attributeLocations={position0:0,componentIndex:1,position1:2,packedAttributes:3,normalA:4,normalB:5,normal:6,variantOffset:7,variantStroke:8,variantExtension:9,
extensionDirection:10,sidenessAtt:11};c.componentColorBindParameters={tex:"uComponentColorTex",invDim:"uComponentColorTexInvDim",unit:2};c.default=e});